{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311e7ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import time\n",
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from statistics import mean\n",
    "import xlwt\n",
    "from tqdm import tqdm\n",
    "\n",
    "session = requests.Session()\n",
    "\n",
    "geocode_cache = {}\n",
    "weather_cache = {}\n",
    "geocode_df = None\n",
    "\n",
    "def geocode_city(city, country=None):\n",
    "    global geocode_cache, geocode_df\n",
    "    if not city or pd.isna(city):\n",
    "        return (None, None)\n",
    "    key = (str(city).strip().lower(), (str(country).strip().lower() if country else None))\n",
    "    if key in geocode_cache:\n",
    "        return geocode_cache[key]\n",
    "\n",
    "    geocode_df = pd.read_excel(os.path.join(os.getcwd(), \"data\", \"worldcities.xlsx\"))\n",
    "\n",
    "    lookup = str(city).strip().lower()\n",
    "    city_col = geocode_df.get(\"city\", pd.Series(dtype=\"str\")).astype(str).str.lower()\n",
    "    ascii_col = geocode_df.get(\"city_ascii\", pd.Series(dtype=\"str\")).astype(str).str.lower()\n",
    "    mask = (city_col == lookup) | (ascii_col == lookup)\n",
    "    if country:\n",
    "        country_col = geocode_df.get(\"country\", pd.Series(dtype=\"str\")).astype(str).str.lower()\n",
    "        mask = mask & (country_col == str(country).strip().lower())\n",
    "\n",
    "    candidates = geocode_df[mask]\n",
    "    if candidates.empty:\n",
    "        geocode_cache[key] = (None, None)\n",
    "        return (None, None)\n",
    "\n",
    "    if \"population\" in candidates.columns:\n",
    "        candidates = candidates.copy()\n",
    "        candidates[\"population\"] = pd.to_numeric(candidates[\"population\"], errors=\"coerce\").fillna(0)\n",
    "        row = candidates.sort_values(\"population\", ascending=False).iloc[0]\n",
    "    else:\n",
    "        row = candidates.iloc[0]\n",
    "\n",
    "    lat = float(row.get(\"lat\")) if not pd.isna(row.get(\"lat\")) else None\n",
    "    lon = float(row.get(\"lng\")) if not pd.isna(row.get(\"lng\")) else None\n",
    "    geocode_cache[key] = (lat, lon)\n",
    "    return (lat, lon)\n",
    "\n",
    "\n",
    "\n",
    "def fetch_weather_mean(lat, lon, date_obj):\n",
    "    if lat is None or lon is None:\n",
    "        return (None, None)\n",
    "\n",
    "    date_str = pd.to_datetime(date_obj, errors=\"coerce\")\n",
    "    if pd.isna(date_str):\n",
    "        return (None, None)\n",
    "    date_str = date_str.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    key = (round(lat, 4), round(lon, 4), date_str)\n",
    "    if key in weather_cache:\n",
    "        return weather_cache[key]\n",
    "\n",
    "    params = {\n",
    "        \"latitude\": lat,\n",
    "        \"longitude\": lon,\n",
    "        \"start_date\": date_str,\n",
    "        \"end_date\": date_str,\n",
    "        \"hourly\": \"temperature_2m,relativehumidity_2m\",\n",
    "        \"timezone\": \"auto\",\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        r = session.get(\"https://archive-api.open-meteo.com/v1/archive\", params=params, timeout=20)\n",
    "        r.raise_for_status()\n",
    "    except requests.HTTPError as e:\n",
    "        print(\"HTTP error fetching weather:\", e, \"response:\", getattr(e.response, \"text\", None))\n",
    "        return (None, None)\n",
    "    except requests.RequestException as e:\n",
    "        print(\"Request exception fetching weather:\", e)\n",
    "        return (None, None)\n",
    "\n",
    "    data = r.json()\n",
    "    hourly = data.get(\"hourly\", {})\n",
    "    times = hourly.get(\"time\", [])\n",
    "    temps = hourly.get(\"temperature_2m\", [])\n",
    "    hums = hourly.get(\"relativehumidity_2m\", [])\n",
    "\n",
    "    daytime_temps = []\n",
    "    daytime_hums = []\n",
    "    for t_str, tp, hm in zip(times, temps, hums):\n",
    "        try:\n",
    "            dt = pd.to_datetime(t_str)\n",
    "        except Exception:\n",
    "            continue\n",
    "        if 6 <= dt.hour <= 18:\n",
    "            daytime_temps.append(tp)\n",
    "            daytime_hums.append(hm)\n",
    "\n",
    "    mean_temp = float(mean(daytime_temps)) if daytime_temps else None\n",
    "    mean_hum = float(mean(daytime_hums)) if daytime_hums else None\n",
    "\n",
    "    time.sleep(0.5)\n",
    "    weather_cache[key] = (mean_temp, mean_hum)\n",
    "    return (mean_temp, mean_hum)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd58b83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows for ./data/2010.xls: 100%|██████████| 2679/2679 [02:59<00:00, 14.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved ./data/2010.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows for ./data/2011.xls: 100%|██████████| 2675/2675 [02:53<00:00, 15.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved ./data/2011.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows for ./data/2012.xls:  12%|█▏        | 318/2607 [00:27<03:14, 11.76it/s]"
     ]
    }
   ],
   "source": [
    "\n",
    "path = \"./data/\"\n",
    "def main(year:str):\n",
    "    input_xls = path + year + \".xls\"\n",
    "    df = pd.read_excel(input_xls)\n",
    "\n",
    "    # parse dates like 1/1/2001 -> 2001-01-01\n",
    "    df[\"Date_parsed\"] = pd.to_datetime(df[\"Date\"], dayfirst=False, errors=\"coerce\")\n",
    "\n",
    "    # prepare result columns\n",
    "    df[\"temp_matchday\"] = None\n",
    "    df[\"humidity_matchday\"] = None\n",
    "\n",
    "    for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Processing rows for \"+input_xls):\n",
    "        court = row.get(\"Court\")\n",
    "        if court == \"Outdoor\":\n",
    "            city = row.get(\"Location\")\n",
    "            date_obj = row.get(\"Date_parsed\")\n",
    "            lat, lon = geocode_city(city)\n",
    "            temp, hum = fetch_weather_mean(lat, lon, date_obj)\n",
    "            df.at[idx, \"temp_matchday\"] = temp\n",
    "            df.at[idx, \"humidity_matchday\"] = hum\n",
    "\n",
    "    out_xls = os.path.join(path, year + \".csv\")\n",
    "    df.to_csv(out_xls, index=False)\n",
    "    print(\"Saved\", out_xls)\n",
    "\n",
    "\n",
    "\n",
    "years = [\"2010\", \"2011\", \"2012\", \"2013\", \"2014\", \"2015\", \"2016\", \"2018\",\"2019\", \"2020\", \"2021\", \"2022\", \"2023\", \"2024\", \"2025\"]\n",
    "for y in years:\n",
    "    main(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc09f9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b3fa65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tennis-pred",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
